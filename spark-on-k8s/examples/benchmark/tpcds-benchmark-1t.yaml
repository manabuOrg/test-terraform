# NOTE: This example requires the following prerequisites before executing the jobs
# 1. Ensure spark-team-a name space exists
# 2. replace <ENTER_YOUR_BUCKET_NAME> with your bucket name
# 3. Ensure you run "analytics/spark-k8s-operator/spark-samples/tpcds-benchmark-data-generation-1t.yaml"  which generates 3 TB input data

---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: tpcds-benchmark-3tb
  namespace: spark-team-a
spec:
  type: Scala
  mode: cluster
  image: ghcr.io/aws-samples/emr-on-eks-benchmark:3.1.2
  imagePullPolicy: IfNotPresent
  sparkVersion: 3.1.2
  mainClass: com.amazonaws.eks.tpcds.BenchmarkSQL
  mainApplicationFile: local:///opt/spark/examples/jars/eks-spark-benchmark-assembly-1.0.jar
  arguments:
    # TPC-DS data location
    - "s3a://<ENTER_YOUR_BUCKET_NAME>/TPCDS-TEST-3T"
    # results location
    - "s3a://<ENTER_YOUR_BUCKET_NAME>/TPCDS-TEST-3T-RESULT"
    # Path to kit in the docker image
    - "/opt/tpcds-kit/tools"
    # Data Format
    - "parquet"
    # Scale factor (in GB)
    - "3000"
    # Number of iterations
    - "1"
    # Optimize queries with hive tables
    - "false"
    # Filter queries, will run all if empty - "q98-v2.4,q99-v2.4,ss_max-v2.4,q95-v2.4"
    - ""
    # Logging set to WARN
    - "true"
  sparkConf:
    "spark.network.timeout": "2000s"
    "spark.executor.heartbeatInterval": "300s"
    # AQE
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.adaptive.localShuffleReader.enabled": "true"
    "spark.sql.adaptive.coalescePartitions.enabled": "true"
    "spark.sql.adaptive.skewJoin.enabled": "true"
    # "spark.sql.adaptive.logLevel": "WARN"
    # IRSA for S3 connection
    "spark.kubernetes.executor.podNamePrefix": "oss-spark-tpcds-2g1000"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "com.amazonaws.auth.WebIdentityTokenCredentialsProvider"
    "spark.hadoop.fs.s3.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version": "2"
    "spark.executor.defaultJavaOptions": "-verbose:gc -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70"
    # Keep pods in a single AZ
    # "spark.kubernetes.node.selector.topology.kubernetes.io/zone": "us-west-1b"
    # "spark.kubernetes.node.selector.eks.amazonaws.com/capacityType": "ON_DEMAND"
  driver:
    volumeMounts: # Points to InstanceStore NVMe SSD for shuffle spill over from memory
      - name: spark-local-dir-1
        mountPath: /data1
        readOnly: false
    initContainers:
      - name: volume-permissions
        image: public.ecr.aws/y4g4v0z7/busybox
        command: [ 'sh', '-c', 'chown -R 185 /mnt/k8s-disks' ]
        volumeMounts:
          - mountPath: "/mnt/k8s-disks"
            name: "spark-local-dir-1"
    cores: 4
    coreLimit: "4.1"
    memory: "5g"
    memoryOverhead: "1000"
    serviceAccount: spark-team-a
    nodeSelector:
      NodeGroupType: "SparkMemoryOptimized"
      karpenter.sh/capacity-type: on-demand
    tolerations:
      - key: "spark-memory-optimized"
        operator: "Exists"
        effect: "NoSchedule"
  executor:
    volumeMounts:
      - name: spark-local-dir-1
        mountPath: /data1
        readOnly: false
    cores: 4
    coreLimit: "4.3"
    memory: "6g"
    memoryOverhead: "2g"
    # 8 executors per node
    instances: 47
    serviceAccount: spark-team-a
    nodeSelector:
      NodeGroupType: "SparkMemoryOptimized"
      karpenter.sh/capacity-type: on-demand
    tolerations:
      - key: "spark-memory-optimized"
        operator: "Exists"
        effect: "NoSchedule"

  restartPolicy:
    type: Never
